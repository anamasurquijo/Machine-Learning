---
title: "Demand Forecasting and Operational Optimization for Capital Bikeshare in Washington, DC"
subtitle: "A Predictive Modeling Feasibility Study to Improve Availability, Efficiency & Rider Experience"
authors: "Ana Mas Urquijo, Mayra Corrales, Vani Gupta"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,              ## Show code and output by default
  warning = FALSE,          ## Hide warnings
  message = FALSE,          ## Hide package loading messages
  fig.width = 10,           ## Wider for side-by-side plots
  fig.height = 5,
  cache = FALSE,            ## Don't cache by default (safer)
  fig.align = 'center'
)

## Load required libraries
library(tidyverse)
library(lubridate)
library(mgcv)
library(nnet)
library(e1071)
library(caret)
library(gridExtra)
library(knitr)
library(corrplot)
library(reshape2)
library(caret)
library(dplyr)
library(tibble)
library(mgcv)



## Set seed for reproducibility
set.seed(81)
```

\newpage

# Executive Summary

This report applies predictive analytics to support Capital Bikeshare in
improving fleet availability and operational performance across
Washington, D.C. Using hourly rental data from 2011 and 2012, we
developed six machine learning models to forecast system demand,
identify peak usage periods, and distinguish behavior between casual and
registered riders. These insights enable smarter decisions for bike
distribution, staffing, and resource allocation—reducing station
imbalances, improving service reliability, and enhancing the rider
experience. The results demonstrate the value of predictive demand
modeling in supporting proactive operational planning and future service
improvements.

# Introduction and Business Context

## Client Context & Needs

For Capital Bikeshare, service reliability depends on ensuring bikes and
docks are available where and when riders need them. Usage varies
significantly across time of day, season, weather, and rider type,
leading to operational challenges such as empty or full stations during
peak periods and excess inventory in low-demand areas. These imbalances
increase redistribution costs and can negatively impact the rider
experience.

To support more proactive decision-making, this analysis focuses on
three core operational questions:

1. **How many bikes will be needed?** (Total demand forecasting)
2. **When will demand peak?** (High-demand period identification)
3. **Who are our users?** (Casual vs. registered user patterns)

Accurate forecasting enables Capital Bikeshare to optimize fleet
allocation, staffing, and maintenance scheduling, helping to reduce
shortages and improve overall service reliability.

Customer feedback from Capital Bikeshare’s member surveys further
reinforces the importance of addressing these needs. For example, 47% of
respondents in the 2012 Member Survey requested more docks at existing
high-demand stations—highlighting bike and dock availability as a
primary driver of customer satisfaction and expansion priorities.

Additionally, Bikeshare plays a key role in Washington, D.C.’s
multimodal transportation network, with more than half of riders using
the service to connect to Metrorail or bus stations, according to survey
findings.

Enhancing reliability through predictive demand modeling can strengthen
these transportation links and support broader mobility goals for the
District.

As system usage continues to grow, data-driven forecasting tools can
guide both operational planning and future network expansion, ensuring
that Capital Bikeshare remains a dependable and competitive
transportation option for both commuters and recreational riders.

## Analytical Approach

We employ six complementary modeling techniques, each addressing specific business needs:

- **Linear Models (LM)**: Baseline demand forecasting with interpretable coefficients
- **Generalized Linear Models (GLM)**: Count-based modeling for casual users (Poisson) and user composition analysis (Binomial)
- **Generalized Additive Models (GAM)**: Capturing complex nonlinear weather effects
- **Neural Networks (NN)**: High-capacity learning for demand classification
- **Support Vector Machines (SVM)**: Robust binary classification for peak demand

\newpage

# Dataset Description

## Data Source

The dataset originates from the UCI Machine Learning Repository's Capital Bikeshare system (Washington D.C.), containing hourly rental records from 2011-2012. This real-world data captures 17,379 hourly observations across diverse weather conditions, seasons, and usage patterns.

**Source**: https://www.kaggle.com/datasets/lakshmi25npathi/bike-sharing-dataset

## Variables Overview

```{r load-data, cache=TRUE}
# Load the hourly dataset
bike <- read.csv("../data/raw/hour.csv")

# Display structure
str(bike)
# colSums(is.na(bike)) ## No NAs returned
```

The dataset includes:

- **Temporal features**: Date, hour, season, month, year, weekday, holiday, working day
- **Weather conditions**: Temperature, humidity, wind speed, weather situation
- **Response variables**: Total rentals, casual users, registered users

All continuous weather variables are normalized (0-1 scale). There are no NAs in the dataset. 

## Variable Transformations

```{r data-prep, cache=TRUE, dependson="load-data"}
## Drop unwanted columns
bike <- bike %>%
  select(-instant, -dteday)

## rename columns for clarity
bike <- bike %>%
  rename(
    weather = weathersit,
    year = yr,
    month = mnth,
    hour = hr,
    humidity = hum,
    count = cnt
  )

## Create analysis dataset with proper factor levels
bike <- bike %>%
  mutate(
    ## Temporal variables as factors
    season = factor(season, levels = 1:4,
                   labels = c("Winter", "Spring", "Summer", "Fall")),
    year = factor(year, levels = 0:1, labels = c("2011", "2012")),
    month = factor(month, levels = 1:12,
                   labels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun",
             "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")),
    hour = factor(hour),
    weekday = factor(weekday, levels = 0:6,
                    labels = c("Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat")),
    holiday = factor(holiday, levels = 0:1, labels = c("No", "Yes")),
    workingday = factor(workingday, levels = 0:1, labels = c("No", "Yes")),
    weather = factor(weather, levels = 1:4,
                       labels = c("Clear or Partly Cloudy", "Mist and Cloudy", "Light Rain or Snow", "Thunder or Ice Storms")),

    ## Response variables for different models
    log_count = log(count),
    high_demand = factor(ifelse(count > median(count), 1, 0),
                        levels = c(0, 1), labels = c("Low", "High")),
    reg_percentage = registered / (count)
  )

str(bike)

## Save processed dataset
write.csv(bike, "../data/processed/bike_cleaned.csv", row.names = FALSE)
saveRDS(bike, "../data/processed/bike_cleaned.rds")
```

## Summary Statistics

Understanding the distinction between casual and registered users is crucial for targeted strategies.

```{r user-type-summary, cache = TRUE}
# Comparative statistics for user types
bike %>%
  summarise(
    Metric = c("Mean", "Median", "Std Dev", "Min", "Max"),
    Casual_Users = c(mean(casual), median(casual), sd(casual), 
                     min(casual), max(casual)),
    Registered_Users = c(mean(registered), median(registered), sd(registered),
                         min(registered), max(registered)),
    Total_Rentals = c(mean(count), median(count), sd(count), min(count), max(count))
  )
```

**Key Insight:**
On average, registered users account for roughly 81% of total rentals, while casual users contribute about 19%indicating that most rides are taken by regular subscribers rather than one-time or occasional users. The difference between mean and median values across all user types also highlights a right-skewed distribution, meaning that while most hours experience relatively low to moderate rental activity, there are a few peak periods with exceptionally high demand that raise the overall average. This skewness is further supported by the large standard deviations, reflecting significant fluctuations in hourly rentals.

\newpage

# Exploratory Data Analysis

## Temporal Patterns

```{r temporal-plots, cache = TRUE}
p1 <- ggplot(bike, aes(x = as.numeric(as.character(hour)), y = count)) +
  geom_point(alpha = 0.15, color = "steelblue", size = 1) +
  geom_smooth(method = "loess", se = TRUE, color = "darkblue", linewidth = 1.2) +
  scale_x_continuous(breaks = seq(0, 23, by = 3)) +
  labs(title = "Hourly Demand Distribution", 
       x = "Hour of Day", y = "Total Rentals") +
  theme_minimal()

p2 <- ggplot(bike, aes(x = season, y = count, fill = season)) +
  geom_boxplot(alpha = 0.7) +
  scale_fill_brewer(palette = "Set2") +
  labs(title = "Seasonal Demand Patterns", 
       x = "Season", y = "Total Rentals") +
  theme_minimal() +
  theme(legend.position = "none")

grid.arrange(p1, p2, ncol = 2)
```

**Key Insights**: Clear bimodal pattern with peaks at 8am and 5pm indicates commuter-driven demand, while overnight hours (0-5am) show minimal activity. Summer and Fall exhibit highest median demand (~180 rentals), while Winter shows lowest (~100 rentals), suggesting weather-dependent cycling behavior and need for seasonal fleet adjustments.


## Weather Effects

```{r weather-plots}
p3 <- ggplot(bike, aes(x = temp, y = count)) +
  geom_point(alpha = 0.2, color = "coral") +
  geom_smooth(method = "loess", se = TRUE, color = "darkred", linewidth = 1.2) +
  labs(title = "Temperature vs. Demand", 
       x = "Normalized Temperature", y = "Total Rentals") +
  theme_minimal()

p4 <- ggplot(bike, aes(x = weather, y = count, fill = weather)) +
  geom_boxplot(alpha = 0.7) +
  scale_fill_brewer(palette = "Set2") +
  labs(title = "Weather Condition Impact", 
       x = "Weather Situation", y = "Total Rentals") +
  theme_minimal() +
  theme(legend.position = "none", axis.text.x = element_text(angle = 45, hjust = 1))

grid.arrange(p3, p4, ncol = 2)
```

**Key Insights**: Strong positive relationship between temperature and demand up to 0.7 normalized temperature, with high variance indicating hour-of-day effects dominate at moderate temperatures. Clear weather yields median ~150 rentals versus ~100 in light rain/snow, representing 33% demand reduction that justifies dynamic pricing and proactive bike re-positioning during poor weather forecasts.


\newpage

# Feature Selection and Correlation Analysis

Before building predictive models, we examine correlations between predictors and the response variable (`count`) to detect multicollinearity and guide feature selection.

```{r correlation-analysis, fig.height=7, fig.width=10, message=FALSE, warning=FALSE}

# Create numeric version of key variables for correlation
bike_numeric <- bike %>%
  mutate(
    season_num     = as.numeric(season),
    year_num       = as.numeric(year),
    month_num      = as.numeric(month),
    hour_num       = as.numeric(hour),
    holiday_num    = as.numeric(holiday),
    weekday_num    = as.numeric(weekday),
    workingday_num = as.numeric(workingday),
    weather_num    = as.numeric(weather)
  ) %>%
  select(
    season_num, year_num, month_num, hour_num,
    holiday_num, weekday_num, workingday_num, weather_num,
    temp, atemp, humidity, windspeed,
    casual, registered, count
  )

# Calculate correlation matrix
cor_matrix <- cor(bike_numeric, use = "complete.obs")

# Visualize correlation matrix
corrplot(
  cor_matrix,
  method       = "color",
  type         = "upper",
  tl.col       = "black",
  tl.srt       = 45,
  tl.cex       = 0.8,
  addCoef.col  = "black",
  number.cex   = 0.6,
  col          = colorRampPalette(c("#6D9EC1", "white", "#E46726"))(200),
  title        = "Correlation Matrix: Predictors and Response Variable (count)",
  mar          = c(0, 0, 2, 0)
)

```

## Correlation Insights for Model Building

```{r correlation-insights, message=FALSE, warning=FALSE}

# Build a data frame with variable names and their correlation with count
cor_with_count <- tibble(
  Variable    = rownames(cor_matrix),
  Correlation = cor_matrix[, "count"]
) %>%
  filter(Variable != "count") %>%
  arrange(desc(abs(Correlation)))

kable(
  head(cor_with_count, 10),
  digits  = 3,
  caption = "Top 10 Correlations with Total Demand (count)"
)

```

**Key Findings for Feature Selection**

1. **Strong and important predictors**  
   - **Temperature (`temp`, ~0.40)** and **feeling temperature (`atemp`, ~0.40)** show moderate positive correlations.  
   - **Registered users (~0.97)** strongly correlate with total demand (mathematically expected).  
   - **Hour (~0.40)** is the most important temporal factor.

2. **Multicollinearity concerns**  
   - `temp` vs `atemp`: correlation ≈ 0.99 → **keep only `temp`**.  
   - `holiday` vs `workingday`: negative correlation but captures different calendar effects → **keep both**.

3. **Weak but relevant predictors**  
   - Humidity: weak negative correlation but meteorologically meaningful.  
   - Windspeed: minimal linear effect; may contribute in nonlinear models (GAM, trees).

4. **Feature selection strategy**  
   - **Drop**: `atemp`, `instant`, `dteday`.  
   - **Keep**: all other calendar & weather variables.  
   - **Explore interactions**:  
     - `temp:season` (temperature effects differ by season)  
     - `hour:workingday` (commuter vs leisure patterns)

\newpage



# Model Development

## Train-Test Split Strategy

To evaluate model performance objectively, we split the data into training (80%) and testing (20%) sets. The training set is used to fit models, while the testing set provides an unbiased assessment of how well models generalize to new data.

```{r train-test-split, cache=TRUE, dependson="data-prep"}
# Create stratified split for high_demand to ensure balanced classes
train_idx <- createDataPartition(bike$high_demand, p = 0.8, list = FALSE)
train <- bike[train_idx, ]
test <- bike[-train_idx, ]

cat("Training observations:", nrow(train), "\n")
cat("Testing observations:", nrow(test), "\n")
cat("\nClass distribution in training set:\n")
table(train$high_demand) %>% prop.table() %>% print()
cat("\nClass distribution in test set:\n")
table(test$high_demand) %>% prop.table() %>% print()
```

**Why we chose an 80/20:Train/Test Split? **:

1. **Prevents Overfitting**: If we evaluate models on the same data used for training, complex models (like neural networks) will appear artificially perfect. The test set reveals true generalization performance.

2. **Simulates Real-World Deployment**: In production, models predict on future, unseen data. The test set mimics this scenario, showing how models perform on "new" hours the system hasn't encountered.

3. **Enables Fair Comparison**: By evaluating all models on identical test data, we ensure performance differences reflect model quality, not data variation.

4. **Stratified Sampling**: We use `createDataPartition()` to maintain similar class distribution in both sets, preventing train-test distribution mismatch.

**Business Relevance**: A model with 90% training accuracy but 60% test accuracy is unreliable for operational planning. The test set ensures we deploy models that actually work when bike demand forecasts matter most.

## Linear Model (LM) - Total Demand Forecasting

We model log-transformed total rentals to handle the multiplicative nature of demand (amounts should be log-transformed). This provides interpretable coefficients for stakeholders.

```{r lm-model, cache=TRUE, dependson="train-test-split"}
# Check if model already exists
if (file.exists("../models/lm_model.rds")) {
  lm_model <- readRDS("../models/lm_model.rds")
} else {
  # Fit comprehensive linear model with interactions
  # Note: Using temp (not atemp) based on correlation analysis
  lm_model <- lm(log_cnt ~ season + yr + mnth + hr + holiday + weekday + 
                   workingday + weathersit + temp + hum + windspeed + 
                   temp:season + hr:workingday + temp:weathersit,
                 data = train)
  # Save model
  saveRDS(lm_model, "../models/lm_model.rds")
}

# Model summary (truncated for brevity)
summary(lm_model)$coefficients[1:10, ] %>% 
  kable(digits = 3, caption = "Linear Model Coefficients (First 10)")

# Predictions and performance
lm_pred <- exp(predict(lm_model, newdata = test)) - 1  # Back-transform
lm_rmse <- sqrt(mean((test$cnt - lm_pred)^2))
lm_r2 <- cor(test$cnt, lm_pred)^2

cat("\nLinear Model Performance:\n")
cat("RMSE:", round(lm_rmse, 2), "\n")
cat("R-squared:", round(lm_r2, 3), "\n")
```

**Interpretation**: Year 2012 shows significant demand increase (exp(coef) ≈ 2x growth), indicating business expansion. Temperature coefficient (~3.5) suggests a 1-unit increase in normalized temperature multiplies demand by exp(3.5) ≈ 33 times (across full range). Working day interactions reveal distinct commuter vs. leisure patterns.

**Business Value**: Provides baseline forecasts for daily/hourly bike allocation with clear seasonal adjustments.

## GLM Poisson - Casual User Modeling

Casual users represent growth opportunities. We model their counts using Poisson regression to respect the discrete nature of this variable.

### Model choice and dispersion
The count model was estimated with a Poisson GLM and then re-estimated using a quasi-Poisson family to account for overdispersion. This method flagged certain coefficients that lost significance under quasi fit, specifically severe weather conditions. The quasi-Poisson dispersion parameter was estimated at φ ≈ 9.34, indicating substantially higher variance than a Poisson model assumes.

```{r glm-poisson, cache=TRUE, dependson="train-test-split"}
# Check if model already exists
if (file.exists("../models/glm_poisson.rds")) {
  glm_poisson <- readRDS("../models/glm_poisson.rds")
} else {
  # Fit Poisson GLM for casual users
  glm_poisson <- glm(casual ~ season + year + hour + holiday + weekday + 
                       weather + temp + humidity + windspeed,
                     family = quasipoisson(link = "log"),
                     data = train)
  # Save model
  saveRDS(glm_poisson, "../models/glm_poisson.rds")
}

# Key coefficients
summary(glm_poisson)

# Predictions and performance
glm_pois_pred <- predict(glm_poisson, newdata = test, type = "response")
glm_pois_rmse <- sqrt(mean((test$casual - glm_pois_pred)^2))
glm_pois_mae <- mean(abs(test$casual - glm_pois_pred))
glm_pois_r_squared <- cor(test$casual, glm_pois_pred)^2

cat("\nPoisson GLM Performance:\n")
cat("MAE:", round(glm_pois_mae, 2), "\n")
cat("R²:", round(glm_pois_r_squared, 2), "\n")
```
### Interpretation

**Baseline Prediction**: In Winter, on a Sunday at midnight (hour 0), with clear weather in 2011, the predicted casual demand is exp(1.327) ≈ 4 bikes.

**Key Demand Drivers**:

_Hour of day_: Midday hours (12-2pm) multiply demand by exp(1.72-1.78) ≈ 5.6-5.9× compared to midnight.
_Temperature_: Going from cold (0.2) to warm (0.8) increases casual riders by exp(2.15×0.6) ≈ 3.5×.
_Annual growth_: 2012 shows exp(0.37) ≈ 1.45× higher demand than 2011, indicating 45% year-over-year growth in casual users.
_Holiday boost_: Holidays increase casual demand by exp(0.58) ≈ 78% increase, validating leisure-rider targeting.

### Business Value: Target mid-day marketing campaigns for tourists/leisure riders during holidays, especially on warm days.

The Poisson model predicts casual rider demand with ±14 bikes accuracy on average and captures 73% of demand patterns. This enables reliable weekend capacity planning and holiday staffing adjustments, though real-time adjustments may still be needed for unexpected events. 

## Generalized Linear Models – Binomial

To analyze **who drives demand** at different times, we model the probability that an individual ride in a given hour is from a **registered user** rather than a casual rider.  
Each hour consists of a number of “trials” (rides), where each outcome is either **registered** (success) or **casual** (failure).  
This formulation satisfies the requirements of a **Binomial GLM with a logit link**.

```{r glm-binomial, message=FALSE, warning=FALSE}

# Define binomial response: successes = registered; failures = casual
train$reg_count   <- train$registered
train$total_count <- train$count

test$reg_count    <- test$registered
test$total_count  <- test$count

# Load or fit the Binomial GLM
if (file.exists("../models/glm_binomial.rds")) {
  glm_binomial <- readRDS("../models/glm_binomial.rds")
} else {
  glm_binomial <- glm(
    cbind(reg_count, total_count - reg_count) ~
      season + hour + holiday + workingday + weather + temp + humidity,
    family = binomial(link = "logit"),
    data   = train
  )
  saveRDS(glm_binomial, "../models/glm_binomial.rds")
}

glm_binomial_coefs <- summary(glm_binomial)$coefficients

# Predictions on test set
glm_binom_prob <- predict(glm_binomial, newdata = test, type = "response")

# Classification: which group dominates?
glm_binom_pred_class <- ifelse(glm_binom_prob > 0.5, "registered-majority", "casual-majority")
glm_binom_true_class <- ifelse(test$registered > test$casual, "registered-majority", "casual-majority")
glm_binom_accuracy   <- mean(glm_binom_pred_class == glm_binom_true_class)

cat("Binomial GLM accuracy:", round(glm_binom_accuracy, 3), "\n")

kable(
  glm_binomial_coefs,
  digits  = 3,
  caption = "Binomial GLM – Probability that a rider is registered"
)
```

### Interpretation

**Baseline Prediction**: Under winter, midnight, non-holiday, non-working-day, clear-weather conditions, the model predicts a **registered-user share of ~87%** (exp(1.942)).

**Key Demand Drivers**:

- **Workingday**: Registered riders increase by **exp(0.911) ≈ 2.49×**, confirming strong commuter dominance.  
- **Hour of day**: Morning peaks (5–8am) expand registered share (**exp(0.64–0.93) ≈ 1.9–2.5×**).  
  Midday (10–15h) reduces registered share by **exp(–0.47 to –0.65) ≈ 40–48%**.  
- **Season**: Spring/Summer reduce registered usage by **exp(–0.303 to –0.092) ≈ 9–26%**, reflecting higher casual/tourist activity.  
- **Weather**: Light rain/snow increases registered share by **exp(0.171) ≈ 1.19×** as casual users drop off more quickly.  
- **Temperature**: Warmer conditions reduce registered demand by **exp(–1.513) ≈ 0.22×**, a strong **78% shift** toward casual riders.

Overall, the model achieves **high accuracy**, capturing clear commuter vs. leisure behavior patterns across time, weather, and seasonality.

### Business Value

This model identifies **who uses the service under which conditions**, enabling targeted operational and marketing actions:

- **Commuter segments**: Morning and working-day peaks support corporate plans, commuter passes, and weekday-focused resource allocation.  
- **Tourist/leisure segments**: Warm midday hours are dominated by casual riders → ideal for tourist promotions, flexible passes, and leisure-focused campaigns.  
- **Weather-aware planning**: Rain increases registered share; warm sunny days increase casual demand → adjust supply accordingly.  
- **Operational optimization**: Redistribute bikes based on dominant rider type—commuter routes in the morning, leisure/tourist zones in warm afternoons.

##

## Generalized Additive Model (GAM)

To capture **nonlinear relationships** between weather conditions and bike demand, we use a **Generalized Additive Model (GAM)**.  
This model allows **flexible smooth functions** for temperature, perceived temperature, humidity, and wind speed, while keeping seasonal and calendar effects linear.  
GAMs are ideal when relationships are curved or seasonal patterns vary gradually.

```{r gam-model, message=FALSE, warning=FALSE}


# Load or fit the GAM model
if (file.exists("../models/gam_model.rds")) {
  gam_model <- readRDS("../models/gam_model.rds")
} else {
  gam_model <- gam(
    count ~ 
      s(temp) +
      s(atemp) +
      s(humidity) +
      s(windspeed) +
      season + month + hour + holiday + workingday + weather,
    data = train,
    family = poisson(link = "log")
  )
  saveRDS(gam_model, "../models/gam_model.rds")
}

gam_summary <- summary(gam_model)

kable(
  gam_summary$p.table,
  digits  = 3,
  caption = "GAM – Parametric Terms"
)

kable(
  gam_summary$s.table,
  digits  = 3,
  caption = "GAM – Smooth Terms"
)
```

### Interpretation

**Baseline Prediction**: In winter, during January, at midnight on a non-working, non-holiday with clear weather, the GAM predicts an average demand of **exp(3.813) ≈ 45 bikes per hour**.

**Key Demand Drivers**:

- **Season**: Compared to winter, demand increases by  
  **exp(0.260) ≈ 1.30× in spring**, **exp(0.313) ≈ 1.37× in summer**, and  
  **exp(0.473) ≈ 1.60× in fall**, confirming overall higher usage in warmer seasons.

- **Hour of day**:  
  Demand is very low in the early night (e.g. hour 3: β = –1.443).  
  From the morning commute onwards it rises sharply, with peaks around  
  **hour 8 (β = 1.933 → exp ≈ 6.9×)** and **hour 17 (β = 1.974 → exp ≈ 7.2×)**  
  relative to midnight, capturing strong rush-hour patterns.

- **Holiday & Workingday**:  
  Holidays slightly reduce demand (**β = –0.122 → exp ≈ 0.89×**),  
  while working days have a small positive effect (**β = 0.019 → exp ≈ 1.02×**).

- **Weather (parametric)**:  
  Mist/Cloudy conditions have a small negative effect (**β = –0.025 → exp ≈ 0.98×**).  
  Light rain or snow reduces expected demand by about **30%**  
  (**β = –0.351 → exp ≈ 0.70×**), while severe storms have only a minor additional effect.

- **Smooth weather effects** (nonlinear terms):  
  All smooth terms are highly significant (p < 0.001), showing strong nonlinear relationships:  
  - *s(temp)* and *s(atemp)*: Demand rises steeply from cold to mild conditions and then flattens or slightly declines at very high temperatures.  
  - *s(humidity)*: Moderate humidity supports demand, while very high humidity strongly reduces it.  
  - *s(windspeed)*: Light wind has little impact, but higher wind speeds reduce demand in a nonlinear way.

Overall, the GAM captures both **sharp hourly peaks** and **smooth nonlinear weather effects**, improving the fit compared to purely linear models.

### Business Value

The GAM provides a detailed picture of **how many bikes are needed under specific weather and time conditions**:

- **Weather-sensitive planning**: Operators can anticipate demand spikes when temperatures move from cold to mild and prepare for drops during heavy rain, high humidity, or strong winds.  
- **Rush-hour capacity management**: Clear peak factors (up to ~7× midnight demand) support precise staffing and bike rebalancing during morning and evening commutes.  
- **Seasonal and promotional timing**: Higher demand in spring, summer, and fall, combined with temperature–humidity curves, helps schedule **leisure-focused campaigns and discounts** when riders are most responsive.  
- **Resilient operations**: By modelling nonlinear responses, the GAM enables more robust forecasting for unusual weather days, reducing both shortages and excess idle bikes.


##


## Neural Network - High Demand Classification

Neural networks excel at complex pattern recognition for binary outcomes. We predict whether demand will be "High" (above median).
A single-hidden-layer neural network (8 neurons) was selected, as this architecture is sufficient for low-dimensional tabular data and avoids overfitting. Model tuning experiments showed that adding more layers did not meaningfully improve classification performance relative to the baseline GLM.

```{r nn-model, cache=TRUE, dependson="train-test-split"}
## Prepare data with numeric predictors only with binary levels set at 0,1
train_nn <- train %>%
  mutate(
    season_num = as.numeric(season),
    year_num = as.numeric(year),
    hour_num = as.numeric(hour),
    holiday_num = as.numeric(holiday) - 1,
    weather_num = as.numeric(weather),
    high_demand_num = as.numeric(high_demand) - 1
  )

test_nn <- test %>%
  mutate(
    season_num = as.numeric(season),
    year_num = as.numeric(year),
    hour_num = as.numeric(hour),
    holiday_num = as.numeric(holiday) - 1,
    weather_num = as.numeric(weather),
    high_demand_num = as.numeric(high_demand) - 1
  )

## Check if model already exists
if (file.exists("../models/nn_model.rds")) {
  nn_model <- readRDS("../models/nn_model.rds")
} else {
  ## Fit neural network (single hidden layer with 8 nodes)
  nn_model <- nnet(high_demand_num ~ season_num + year_num + hour_num + 
                     holiday_num + weather_num + temp + humidity + windspeed,
                   data = train_nn,
                   size = 8,
                   maxit = 200,
                   trace = FALSE)
  ## Save model
  saveRDS(nn_model, "../models/nn_model.rds")
}

nn_pred_prob <- predict(nn_model, newdata = test_nn, type = "raw")
nn_pred_class <- ifelse(nn_pred_prob > 0.5, "High", "Low")

## Create confusion matrix object with metrics
nn_conf_metrics <- confusionMatrix(
  data = factor(nn_pred_class, levels = c("Low", "High")),
  reference = factor(test$high_demand, levels = c("Low", "High")),
  positive = "High"  # Define which class is "positive"
)
nn_accuracy <- nn_conf_metrics$overall['Accuracy']

print(nn_conf_metrics)
```

###Interpretation

The model captures complex relationships and interactions, achieving 87.8% balanced accuracy, confirming that the model performs consistently across both high and low demand classes. It successfully identifies 91% of high-demand hours. This enables proactive bike redistribution, though 276 false alarms (15% false positive rate) suggest occasional over-preparation. 

###Business Value: Trigger alerts for high-demand shifts, enabling proactive bike redistribution.

This model is appropriate for operational planning because underestimating demand is more costly than over-preparing.

## Support Vector Machine - Robust Demand Classification

SVMs provide an alternative robust classifier, particularly effective with nonlinear decision boundaries.

```{r svm-model, cache=TRUE, dependson="train-test-split"}
# Check if model already exists
if (file.exists("models/svm_model.rds")) {
  svm_model <- readRDS("models/svm_model.rds")
} else {
  # Fit SVM with radial basis kernel
  svm_model <- svm(high_demand ~ season + yr + hr + holiday + workingday + 
                     weathersit + temp + hum + windspeed,
                   data = train,
                   kernel = "radial",
                   cost = 10,
                   gamma = 0.1)
  # Save model
  saveRDS(svm_model, "models/svm_model.rds")
}

# Predictions and performance
svm_pred <- predict(svm_model, newdata = test)
svm_accuracy <- mean(svm_pred == test$high_demand)
svm_conf <- table(Predicted = svm_pred, Actual = test$high_demand)

cat("\nSVM Performance:\n")
cat("Accuracy:", round(svm_accuracy * 100, 1), "%\n")
print(svm_conf)
```

**Interpretation**: SVM achieves comparable accuracy to neural networks with potentially better generalization on new patterns. The radial kernel captures complex boundaries between high/low demand states.

**Business Value**: Provides complementary classification for ensemble decision-making; reduces false negatives (missed high-demand periods).

\newpage

# Model Comparison and Cross-Validation

We perform 5-fold cross-validation on SVMs with different hyperparameters to optimize classification:

```{r cv-svm}
# Cross-validation for SVM cost parameter
cost_values <- c(1, 10, 100)
cv_results <- data.frame(Cost = numeric(), Accuracy = numeric())

for (cost_val in cost_values) {
  cv_folds <- createFolds(train$high_demand, k = 5)
  fold_accuracy <- numeric(5)
  
  for (i in 1:5) {
    fold_train <- train[-cv_folds[[i]], ]
    fold_valid <- train[cv_folds[[i]], ]
    
    svm_cv <- svm(high_demand ~ season + yr + hr + holiday + workingday + 
                    weathersit + temp + hum + windspeed,
                  data = fold_train,
                  kernel = "radial",
                  cost = cost_val,
                  gamma = 0.1)
    
    fold_pred <- predict(svm_cv, fold_valid)
    fold_accuracy[i] <- mean(fold_pred == fold_valid$high_demand)
  }
  
  cv_results <- rbind(cv_results, 
                      data.frame(Cost = cost_val, 
                                Accuracy = mean(fold_accuracy)))
}

cv_results %>%
  kable(digits = 3, caption = "SVM Cross-Validation Results")
```

**Findings**: Cost parameter of 10 provides optimal balance between complexity and generalization.

## Overall Model Performance Summary

```{r performance-summary}
# Compile all performance metrics
performance <- data.frame(
  Model = c("Linear Model", "GAM", "Poisson GLM", "Binomial GLM", 
            "Neural Network", "SVM"),
  Task = c("Total Demand", "Total Demand", "Casual Users", "User Composition",
           "High Demand Class", "High Demand Class"),
  Metric = c(paste("RMSE:", round(lm_rmse, 2)),
             paste("RMSE:", round(gam_rmse, 2)),
             paste("RMSE:", round(glm_pois_rmse, 2)),
             paste("Accuracy:", round(glm_binom_accuracy * 100, 1), "%"),
             paste("Accuracy:", round(nn_accuracy * 100, 1), "%"),
             paste("Accuracy:", round(svm_accuracy * 100, 1), "%")),
  Business_Use = c("Daily forecasting", "Weather-sensitive forecasting",
                   "Marketing targeting", "Membership strategy",
                   "Alert system", "Operational planning")
)

kable(performance, caption = "Model Performance and Business Applications")
```

\newpage

# Conclusions

## Key Findings

Our comprehensive analysis reveals five actionable insights for optimizing bike-sharing operations:

1. **Temporal Patterns Drive Demand**: Clear commuter peaks (8am, 5-6pm) and seasonal variation (Fall peak, Spring trough) enable predictable bike allocation. The 2011-2012 growth trajectory (~2x increase) demonstrates market expansion potential.

2. **Weather Sensitivity Varies by Metric**: Temperature optimum around 0.6-0.7 normalized scale; light rain reduces demand by 40%. However, weather has minimal effect on registered vs. casual user composition, suggesting loyal riders adapt while casual users avoid adverse conditions.

3. **User Segmentation Informs Strategy**: Registered users dominate working days (82%), while casual users increase weekends. This validates targeted approaches: commuter-route optimization weekdays, leisure-route emphasis weekends.

4. **Nonlinear Relationships Matter**: GAM reveals complex weather effects missed by linear models, particularly temperature's inverted-U relationship. This justifies dynamic pricing/availability strategies.

5. **Classification Models Enable Proactive Management**: Neural networks and SVMs predict high-demand periods with >85% accuracy, allowing proactive bike redistribution before shortages occur.

## Operational Recommendations

**Immediate Actions** (Next Quarter):
- Implement hour-based bike allocation: 40% surplus at 7-9am and 5-7pm near business districts
- Launch targeted casual-user campaigns during holidays/weekends at scenic routes
- Install weather-protected stations in high-wind or frequent-rain areas

**Strategic Initiatives** (Next Year):
- Deploy high-demand alert system using NN/SVM ensemble
- Expand Fall capacity (+30% fleet) to capitalize on peak seasonal demand
- Develop two-tier pricing: dynamic pricing for casual users, stable rates for registered users

## Limitations

While our models demonstrate strong predictive power, several limitations warrant consideration:

1. **Data Scope**: Analysis based on 2011-2012 data; post-pandemic behavior may differ significantly
2. **External Factors**: Models omit events (concerts, sports), construction, or transit disruptions
3. **Spatial Dynamics**: Hourly aggregates mask station-level variation; neighborhood-specific models would improve redistribution logistics
4. **Causal Inference**: Predictive models identify correlations but cannot confirm causal mechanisms (e.g., weather causes demand vs. both influenced by third factor)

## Future Work

To enhance decision-support capabilities, we recommend:

1. **Spatial Modeling**: Develop station-level forecasts using geographic data and network flow analysis
2. **Temporal Granularity**: 15-minute predictions for intra-hour variability during peak periods
3. **Ensemble Methods**: Combine model predictions (e.g., weighted average of LM, GAM, NN) for robust forecasts
4. **Real-time Integration**: Deploy models via API for live dashboard updating as conditions change
5. **Causal Analysis**: Conduct A/B tests for pricing/availability interventions to validate model assumptions

\newpage

# Use of Generative AI

## How We Used Generative AI

We used Generative AI strictly as a **supportive tool** to complement our own work. For all modelling, coding, and interpretation tasks, we first attempted to solve them independently. We only consulted AI when we needed clarification of error messages, help understanding unexpected behaviour in RMarkdown, or assistance rephrasing text to improve clarity. All statistical decisions, model specifications, and implementations were fully developed by us.

### How we used Generative AI
We relied on AI only to:
- clarify small, practical issues (e.g., RMarkdown chunk formatting, syntax questions),
- rephrase or refine text that we had already written for better readability,
- obtain short reminders of concepts we already understood from the lectures.

### What was easy vs. challenging
AI was useful for simple and well-defined questions, but it was **not capable of evaluating theoretical correctness**. For example, during the Binomial GLM section, AI could give general explanations, but determining whether our response variable and predictors met the theoretical requirements for a proper binomial model was only possible after revisiting the **lecture notes and course material**. This conceptual validation required our own understanding and could not be outsourced.

### Critical reflection
Throughout the project, we made sure to:
- carefully review any explanations provided by AI,
- ensure that our interpretations were consistent with our dataset and modelling framework,
- verify all clarifications against the theory taught in class,
- maintain a unified writing style across team members and avoid any overly “AI-like” phrasing.

Overall, Generative AI provided limited but helpful support for **minor clarifications and text refinement**, while all core modelling work, statistical reasoning, and final decisions were entirely carried out by us based on the course content.


\newpage

# Appendix: Session Information

```{r session-info}
sessionInfo()
```