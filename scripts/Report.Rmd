---
title: "Predictive Analytics for Bike Sharing Demand Optimization"
subtitle: "A Comprehensive Machine Learning Analysis for Operational Excellence"
authors: "Ana Mas Urquijo, Mayra Corrales, Vani Gupta"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,              ## Show code and output by default
  warning = FALSE,          ## Hide warnings
  message = FALSE,          ## Hide package loading messages
  fig.width = 10,           ## Wider for side-by-side plots
  fig.height = 5,
  cache = FALSE,            ## Don't cache by default (safer)
  fig.align = 'center'
)

## Load required libraries
library(tidyverse)
library(lubridate)
library(mgcv)
library(nnet)
library(e1071)
library(caret)
library(gridExtra)
library(knitr)
library(corrplot)
library(reshape2)
library(caret)

## Set seed for reproducibility
set.seed(81)
```

\newpage

# Executive Summary

This analysis provides actionable insights for optimizing bike-sharing operations through predictive modeling. Using hourly rental data spanning two years, we developed six complementary machine learning models to forecast demand patterns, enabling strategic decisions about bike distribution, staffing, and resource allocation. Our models predict total demand, identify high-traffic periods, and distinguish usage patterns between casual and registered users, directly supporting operational efficiency and customer satisfaction goals.

# Introduction and Business Context

## Client Needs

As a bike-sharing company, operational excellence depends on anticipating demand fluctuations. Mis-allocating resources leads to customer dissatisfaction (bike shortages) or wasted capacity (excess bikes). This analysis addresses three critical business questions:

1. **How many bikes will be needed?** (Total demand forecasting)
2. **When will demand peak?** (High-demand period identification)
3. **Who are our users?** (Casual vs. registered user patterns)

## Analytical Approach

We employ six complementary modeling techniques, each addressing specific business needs:

- **Linear Models (LM)**: Baseline demand forecasting with interpretable coefficients
- **Generalized Linear Models (GLM)**: Count-based modeling for casual users (Poisson) and user composition analysis (Binomial)
- **Generalized Additive Models (GAM)**: Capturing complex nonlinear weather effects
- **Neural Networks (NN)**: High-capacity learning for demand classification
- **Support Vector Machines (SVM)**: Robust binary classification for peak demand

\newpage

# Dataset Description

## Data Source

The dataset originates from the UCI Machine Learning Repository's Capital Bikeshare system (Washington D.C.), containing hourly rental records from 2011-2012. This real-world data captures 17,379 hourly observations across diverse weather conditions, seasons, and usage patterns.

**Source**: https://www.kaggle.com/datasets/lakshmi25npathi/bike-sharing-dataset

## Variables Overview

```{r load-data, cache=TRUE}
# Load the hourly dataset
bike <- read.csv("../data/raw/hour.csv")

# Display structure
str(bike)
# colSums(is.na(bike)) ## No NAs returned
```

The dataset includes:

- **Temporal features**: Date, hour, season, month, year, weekday, holiday, working day
- **Weather conditions**: Temperature, humidity, wind speed, weather situation
- **Response variables**: Total rentals, casual users, registered users

All continuous weather variables are normalized (0-1 scale). There are no NAs in the dataset. 

## Variable Transformations

```{r data-prep, cache=TRUE, dependson="load-data"}
## Drop unwanted columns
bike <- bike %>%
  select(-instant, -dteday)

## rename columns for clarity
bike <- bike %>%
  rename(
    weather = weathersit,
    year = yr,
    month = mnth,
    hour = hr,
    humidity = hum,
    count = cnt
  )

## Create analysis dataset with proper factor levels
bike <- bike %>%
  mutate(
    ## Temporal variables as factors
    season = factor(season, levels = 1:4,
                   labels = c("Winter", "Spring", "Summer", "Fall")),
    year = factor(year, levels = 0:1, labels = c("2011", "2012")),
    month = factor(month, levels = 1:12,
                   labels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun",
             "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")),
    hour = factor(hour),
    weekday = factor(weekday, levels = 0:6,
                    labels = c("Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat")),
    holiday = factor(holiday, levels = 0:1, labels = c("No", "Yes")),
    workingday = factor(workingday, levels = 0:1, labels = c("No", "Yes")),
    weather = factor(weather, levels = 1:4,
                       labels = c("Clear or Partly Cloudy", "Mist and Cloudy", "Light Rain or Snow", "Thunder or Ice Storms")),

    ## Response variables for different models
    log_count = log(count),
    high_demand = factor(ifelse(count > median(count), 1, 0),
                        levels = c(0, 1), labels = c("Low", "High")),
    reg_percentage = registered / (count)
  )

str(bike)

## Save processed dataset
write.csv(bike, "../data/processed/bike_cleaned.csv", row.names = FALSE)
saveRDS(bike, "../data/processed/bike_cleaned.rds")
```

## Summary Statistics

Understanding the distinction between casual and registered users is crucial for targeted strategies.

```{r user-type-summary}
# Comparative statistics for user types
bike %>%
  summarise(
    Metric = c("Mean", "Median", "Std Dev", "Min", "Max"),
    Casual_Users = c(mean(casual), median(casual), sd(casual), 
                     min(casual), max(casual)),
    Registered_Users = c(mean(registered), median(registered), sd(registered),
                         min(registered), max(registered)),
    Total_Rentals = c(mean(count), median(count), sd(count), min(count), max(count))
  )
```

**Key Insight:**
On average, registered users account for roughly 81% of total rentals, while casual users contribute about 19%indicating that most rides are taken by regular subscribers rather than one-time or occasional users. The difference between mean and median values across all user types also highlights a right-skewed distribution, meaning that while most hours experience relatively low to moderate rental activity, there are a few peak periods with exceptionally high demand that raise the overall average. This skewness is further supported by the large standard deviations, reflecting significant fluctuations in hourly rentals.

\newpage

# Exploratory Data Analysis

## Temporal Patterns

```{r temporal-plots}
p1 <- ggplot(bike, aes(x = as.numeric(as.character(hour)), y = count)) +
  geom_point(alpha = 0.15, color = "steelblue", size = 1) +
  geom_smooth(method = "loess", se = TRUE, color = "darkblue", linewidth = 1.2) +
  scale_x_continuous(breaks = seq(0, 23, by = 3)) +
  labs(title = "Hourly Demand Distribution", 
       x = "Hour of Day", y = "Total Rentals") +
  theme_minimal()

p2 <- ggplot(bike, aes(x = season, y = count, fill = season)) +
  geom_boxplot(alpha = 0.7) +
  scale_fill_brewer(palette = "Set2") +
  labs(title = "Seasonal Demand Patterns", 
       x = "Season", y = "Total Rentals") +
  theme_minimal() +
  theme(legend.position = "none")

grid.arrange(p1, p2, ncol = 2)
```

**Key Insights**: Clear bimodal pattern with peaks at 8am and 5pm indicates commuter-driven demand, while overnight hours (0-5am) show minimal activity. Summer and Fall exhibit highest median demand (~180 rentals), while Winter shows lowest (~100 rentals), suggesting weather-dependent cycling behavior and need for seasonal fleet adjustments.


## Weather Effects

```{r weather-plots}
p3 <- ggplot(bike, aes(x = temp, y = count)) +
  geom_point(alpha = 0.2, color = "coral") +
  geom_smooth(method = "loess", se = TRUE, color = "darkred", linewidth = 1.2) +
  labs(title = "Temperature vs. Demand", 
       x = "Normalized Temperature", y = "Total Rentals") +
  theme_minimal()

p4 <- ggplot(bike, aes(x = weather, y = count, fill = weather)) +
  geom_boxplot(alpha = 0.7) +
  scale_fill_brewer(palette = "Set2") +
  labs(title = "Weather Condition Impact", 
       x = "Weather Situation", y = "Total Rentals") +
  theme_minimal() +
  theme(legend.position = "none", axis.text.x = element_text(angle = 45, hjust = 1))

grid.arrange(p3, p4, ncol = 2)
```

**Key Insights**: Strong positive relationship between temperature and demand up to 0.7 normalized temperature, with high variance indicating hour-of-day effects dominate at moderate temperatures. Clear weather yields median ~150 rentals versus ~100 in light rain/snow, representing 33% demand reduction that justifies dynamic pricing and proactive bike re-positioning during poor weather forecasts.


\newpage

# Feature Selection and Correlation Analysis

Before building predictive models, we examine correlations between variables to identify multicollinearity issues and guide feature selection.

```{r correlation-analysis, fig.height=7, fig.width=10}
# Create numeric version of key variables for correlation
bike_numeric <- bike %>%
  mutate(
    season_num = as.numeric(season),
    yr_num = as.numeric(yr),
    mnth_num = as.numeric(mnth),
    hr_num = as.numeric(hr),
    holiday_num = as.numeric(holiday),
    weekday_num = as.numeric(weekday),
    workingday_num = as.numeric(workingday),
    weathersit_num = as.numeric(weathersit)
  ) %>%
  select(season_num, yr_num, mnth_num, hr_num, holiday_num, weekday_num,
         workingday_num, weathersit_num, temp, atemp, hum, windspeed,
         casual, registered, cnt)

# Calculate correlation matrix
cor_matrix <- cor(bike_numeric, use = "complete.obs")

# Visualize correlation matrix
corrplot(cor_matrix, method = "color", type = "upper", 
         tl.col = "black", tl.srt = 45, tl.cex = 0.8,
         addCoef.col = "black", number.cex = 0.6,
         col = colorRampPalette(c("#6D9EC1", "white", "#E46726"))(200),
         title = "Correlation Matrix: Predictors and Response Variables",
         mar = c(0,0,2,0))
```

## Correlation Insights for Model Building

```{r correlation-table}
# Extract key correlations with response variable (cnt)
cor_with_cnt <- cor_matrix[, "cnt"] %>%
  as.data.frame() %>%
  rename(Correlation = '.') %>%
  arrange(desc(abs(Correlation))) %>%
  filter(row.names(.) != "cnt")

kable(head(cor_with_cnt, 10), digits = 3,
      caption = "Top 10 Correlations with Total Demand (cnt)")
```

**Key Findings for Feature Selection**:

1. **Strong Predictors** (|r| > 0.5):
   - Hour (0.40): Most important temporal feature - must include in all models
   - Temperature (0.63) and Feeling Temperature/atemp (0.63): Highly correlated with each other (r=0.99)
   - Registered users (0.97): Obvious since registered + casual = cnt
   
2. **Multicollinearity Concerns**:
   - **temp vs. atemp**: Nearly perfect correlation (0.99) - we will use only `temp` to avoid redundancy
   - **holiday vs. workingday**: Moderate negative correlation (-0.25) - represent complementary information, keep both
   
3. **Weak but Relevant Predictors**:
   - Humidity (-0.10): Weak negative effect, but theoretically important for weather-based models
   - Windspeed (0.10): Minimal linear correlation, but may have nonlinear effects captured by GAM
   
4. **Feature Selection Strategy**:
   - **Drop**: `atemp` (redundant with temp), `instant`, `dteday` (already captured by mnth/yr/hr)
   - **Keep**: All other variables provide unique information
   - **Interactions to explore**: temp:season, hr:workingday (commuter vs. leisure patterns)

This analysis justifies our model specifications and ensures we avoid multicollinearity issues that could inflate standard errors and destabilize coefficient estimates.

\newpage

# Model Development

## Train-Test Split Strategy

To evaluate model performance objectively, we split the data into training (80%) and testing (20%) sets. The training set is used to fit models, while the testing set provides an unbiased assessment of how well models generalize to new data.

```{r train-test-split, cache=TRUE, dependson="data-prep"}
# Create stratified split for high_demand to ensure balanced classes
train_idx <- createDataPartition(bike$high_demand, p = 0.8, list = FALSE)
train <- bike[train_idx, ]
test <- bike[-train_idx, ]

cat("Training observations:", nrow(train), "\n")
cat("Testing observations:", nrow(test), "\n")
cat("\nClass distribution in training set:\n")
table(train$high_demand) %>% prop.table() %>% print()
cat("\nClass distribution in test set:\n")
table(test$high_demand) %>% prop.table() %>% print()
```

**Why we chose an 80/20:Train/Test Split? **:

1. **Prevents Overfitting**: If we evaluate models on the same data used for training, complex models (like neural networks) will appear artificially perfect. The test set reveals true generalization performance.

2. **Simulates Real-World Deployment**: In production, models predict on future, unseen data. The test set mimics this scenario, showing how models perform on "new" hours the system hasn't encountered.

3. **Enables Fair Comparison**: By evaluating all models on identical test data, we ensure performance differences reflect model quality, not data variation.

4. **Stratified Sampling**: We use `createDataPartition()` to maintain similar class distribution in both sets, preventing train-test distribution mismatch.

**Business Relevance**: A model with 90% training accuracy but 60% test accuracy is unreliable for operational planning. The test set ensures we deploy models that actually work when bike demand forecasts matter most.

## Linear Model (LM) - Total Demand Forecasting

We model log-transformed total rentals to handle the multiplicative nature of demand (amounts should be log-transformed). This provides interpretable coefficients for stakeholders.

```{r lm-model, cache=TRUE, dependson="train-test-split"}
# Check if model already exists
if (file.exists("../models/lm_model.rds")) {
  lm_model <- readRDS("../models/lm_model.rds")
} else {
  # Fit comprehensive linear model with interactions
  # Note: Using temp (not atemp) based on correlation analysis
  lm_model <- lm(log_cnt ~ season + yr + mnth + hr + holiday + weekday + 
                   workingday + weathersit + temp + hum + windspeed + 
                   temp:season + hr:workingday + temp:weathersit,
                 data = train)
  # Save model
  saveRDS(lm_model, "../models/lm_model.rds")
}

# Model summary (truncated for brevity)
summary(lm_model)$coefficients[1:10, ] %>% 
  kable(digits = 3, caption = "Linear Model Coefficients (First 10)")

# Predictions and performance
lm_pred <- exp(predict(lm_model, newdata = test)) - 1  # Back-transform
lm_rmse <- sqrt(mean((test$cnt - lm_pred)^2))
lm_r2 <- cor(test$cnt, lm_pred)^2

cat("\nLinear Model Performance:\n")
cat("RMSE:", round(lm_rmse, 2), "\n")
cat("R-squared:", round(lm_r2, 3), "\n")
```

**Interpretation**: Year 2012 shows significant demand increase (exp(coef) ≈ 2x growth), indicating business expansion. Temperature coefficient (~3.5) suggests a 1-unit increase in normalized temperature multiplies demand by exp(3.5) ≈ 33 times (across full range). Working day interactions reveal distinct commuter vs. leisure patterns.

**Business Value**: Provides baseline forecasts for daily/hourly bike allocation with clear seasonal adjustments.

## GLM Poisson - Casual User Modeling

Casual users represent growth opportunities. We model their counts using Poisson regression to respect the discrete nature of this variable.

```{r glm-poisson, cache=TRUE, dependson="train-test-split"}
# Check if model already exists
if (file.exists("../models/glm_poisson.rds")) {
  glm_poisson <- readRDS("../models/glm_poisson.rds")
} else {
  # Fit Poisson GLM for casual users
  glm_poisson <- glm(casual ~ season + year + hour + holiday + weekday + 
                       weather + temp + humidity + windspeed,
                     family = poisson(link = "log"),
                     data = train)
  # Save model
  saveRDS(glm_poisson, "../models/glm_poisson.rds")
}

# Key coefficients
summary(glm_poisson)

# Predictions and performance
glm_pois_pred <- predict(glm_poisson, newdata = test, type = "response")
glm_pois_rmse <- sqrt(mean((test$casual - glm_pois_pred)^2))
glm_pois_mae <- mean(abs(test$casual - glm_pois_pred))
glm_pois_r_squared <- cor(test$casual, glm_pois_pred)^2

cat("\nPoisson GLM Performance:\n")
cat("MAE:", round(glm_pois_mae, 2), "\n")
cat("R²:", round(glm_pois_r_squared, 2), "\n")
```
### Interpretation

**Baseline Prediction**: In Winter, on a Sunday at midnight (hour 0), with clear weather in 2011, the predicted casual demand is exp(1.327) ≈ 4 bikes.

**Key Demand Drivers**:

_Hour of day_: Midday hours (12-2pm) multiply demand by exp(1.72-1.78) ≈ 5.6-5.9× compared to midnight.
_Temperature_: Going from cold (0.2) to warm (0.8) increases casual riders by exp(2.15×0.6) ≈ 3.5×.
_Annual growth_: 2012 shows exp(0.37) ≈ 1.45× higher demand than 2011, indicating 45% year-over-year growth in casual users.
_Weather penalty_: Light rain/snow reduces demand by exp(-0.63) ≈ 47% reduction, while severe weather (thunder/ice) cuts it by exp(-1.30) ≈ 73% reduction.
_Holiday boost_: Holidays increase casual demand by exp(0.58) ≈ 78% increase, validating leisure-rider targeting.

### Business Value: Target mid-day marketing campaigns for tourists/leisure riders during holidays.

The Poisson model predicts casual rider demand with ±14 bikes accuracy on average and captures 73% of demand patterns. This enables reliable weekend capacity planning and holiday staffing adjustments, though real-time adjustments may still be needed for unexpected events. 

## GLM Binomial - User Composition Analysis

Understanding the proportion of registered users helps capacity planning. We model registration proportion using binomial regression.

```{r glm-binomial, cache=TRUE, dependson="train-test-split"}
# Create weighted binomial response
train$reg_count <- round(train$reg_prop * train$cnt)
train$total_count <- train$cnt

# Check if model already exists
if (file.exists("../models/glm_binomial.rds")) {
  glm_binomial <- readRDS("../models/glm_binomial.rds")
} else {
  # Fit binomial GLM
  glm_binomial <- glm(cbind(reg_count, total_count - reg_count) ~ 
                        season + hr + holiday + workingday + 
                        weathersit + temp + hum,
                      family = binomial(link = "logit"),
                      data = train)
  # Save model
  saveRDS(glm_binomial, "../models/glm_binomial.rds")
}

# Key coefficients
summary(glm_binomial)$coefficients[1:8, ] %>%
  kable(digits = 3, caption = "Binomial GLM Coefficients (First 8)")

# Calculate accuracy on test set
test$reg_count <- round(test$reg_prop * test$cnt)
test$total_count <- test$cnt
glm_binom_pred_prob <- predict(glm_binomial, newdata = test, type = "response")
glm_binom_pred_count <- round(glm_binom_pred_prob * test$total_count)
glm_binom_accuracy <- mean(abs(test$reg_count - glm_binom_pred_count) / test$total_count < 0.1)

cat("\nBinomial GLM Performance:\n")
cat("Proportion Accuracy (±10%):", round(glm_binom_accuracy * 100, 1), "%\n")
``` = test, type = "response")
glm_binom_pred_count <- round(glm_binom_pred_prob * test$total_count)
glm_binom_accuracy <- mean(abs(test$reg_count - glm_binom_pred_count) / test$total_count < 0.1)

cat("\nBinomial GLM Performance:\n")
cat("Proportion Accuracy (±10%):", round(glm_binom_accuracy * 100, 1), "%\n")
```

**Interpretation**: Working days strongly increase registered user proportion (odds ratio exp(coef) ≈ 3x). Rush hours (7-9am, 5-7pm) maximize registered usage. Weather has minimal effect on user composition.

**Business Value**: Informs membership drive strategies and validates two-tier pricing models.

## Generalized Additive Model (GAM) - Nonlinear Weather Effects

GAMs capture complex, nonlinear relationships that linear models miss, particularly for weather variables.

```{r gam-model, cache=TRUE, dependson="train-test-split"}
# Check if model already exists
if (file.exists("../models/gam_model.rds")) {
  gam_model <- readRDS("../models/gam_model.rds")
} else {
  # Fit GAM with smooth terms for continuous predictors
  gam_model <- gam(log_cnt ~ season + yr + hr + holiday + weekday + 
                     workingday + weathersit +
                     s(temp, k = 10) + s(hum, k = 10) + s(windspeed, k = 10),
                   data = train)
  # Save model
  saveRDS(gam_model, "../models/gam_model.rds")
}

# Model summary
summary(gam_model)

# Predictions and performance
gam_pred <- exp(predict(gam_model, newdata = test)) - 1
gam_rmse <- sqrt(mean((test$cnt - gam_pred)^2))
gam_r2 <- cor(test$cnt, gam_pred)^2

cat("\nGAM Performance:\n")
cat("RMSE:", round(gam_rmse, 2), "\n")
cat("R-squared:", round(gam_r2, 3), "\n")
```

```{r gam-plots, fig.height=8, echo=FALSE, cache=TRUE, dependson="gam-model"}
par(mfrow = c(3, 1))
plot(gam_model, select = 1, main = "Temperature Effect (Smooth)", 
     xlab = "Normalized Temperature", ylab = "Effect on log(Demand)")
plot(gam_model, select = 2, main = "Humidity Effect (Smooth)", 
     xlab = "Normalized Humidity", ylab = "Effect on log(Demand)")
plot(gam_model, select = 3, main = "Windspeed Effect (Smooth)", 
     xlab = "Normalized Windspeed", ylab = "Effect on log(Demand)")
par(mfrow = c(1, 1))
```

**Interpretation**: Temperature shows optimal demand around 0.6-0.7 (mild weather), declining at extremes. Humidity has slight negative effect above 0.6. Windspeed shows minimal impact until strong winds (>0.5) reduce demand.

**Business Value**: Fine-tuned weather-based operational adjustments; consider shelter/covered stations in high-humidity or windy areas.

## Neural Network - High Demand Classification

Neural networks excel at complex pattern recognition for binary outcomes. We predict whether demand will be "High" (above median).

```{r nn-model, cache=TRUE, dependson="train-test-split"}
## Prepare data with numeric predictors only with binary levels set at 0,1
train_nn <- train %>%
  mutate(
    season_num = as.numeric(season),
    year_num = as.numeric(year),
    hour_num = as.numeric(hour),
    holiday_num = as.numeric(holiday) - 1,
    weather_num = as.numeric(weather),
    high_demand_num = as.numeric(high_demand) - 1
  )

test_nn <- test %>%
  mutate(
    season_num = as.numeric(season),
    year_num = as.numeric(year),
    hour_num = as.numeric(hour),
    holiday_num = as.numeric(holiday) - 1,
    weather_num = as.numeric(weather),
    high_demand_num = as.numeric(high_demand) - 1
  )

## Check if model already exists
if (file.exists("../models/nn_model.rds")) {
  nn_model <- readRDS("../models/nn_model.rds")
} else {
  ## Fit neural network (single hidden layer with 8 nodes)
  nn_model <- nnet(high_demand_num ~ season_num + year_num + hour_num + 
                     holiday_num + weather_num + temp + humidity + windspeed,
                   data = train_nn,
                   size = 8,
                   maxit = 200,
                   trace = FALSE)
  ## Save model
  saveRDS(nn_model, "../models/nn_model.rds")
}

nn_pred_prob <- predict(nn_model, newdata = test_nn, type = "raw")
nn_pred_class <- ifelse(nn_pred_prob > 0.5, "High", "Low")

## Create confusion matrix object with metrics
nn_conf_metrics <- confusionMatrix(
  data = factor(nn_pred_class, levels = c("Low", "High")),
  reference = factor(test$high_demand, levels = c("Low", "High")),
  positive = "High"  # Define which class is "positive"
)
nn_accuracy <- nn_conf_metrics$overall['Accuracy']

print(nn_conf_metrics)
```

###Interpretation

The model captures complex relationships and interactions, achieving 87.8% accuracy with high recall (91.4%), meaning it successfully identifies 91% of high-demand hours. This enables proactive bike redistribution, though 276 false alarms (15% false positive rate) suggest occasional over-preparation. 

###Business Value: Trigger alerts for high-demand shifts, enabling proactive bike redistribution.

## Support Vector Machine - Robust Demand Classification

SVMs provide an alternative robust classifier, particularly effective with nonlinear decision boundaries.

```{r svm-model, cache=TRUE, dependson="train-test-split"}
# Check if model already exists
if (file.exists("models/svm_model.rds")) {
  svm_model <- readRDS("models/svm_model.rds")
} else {
  # Fit SVM with radial basis kernel
  svm_model <- svm(high_demand ~ season + yr + hr + holiday + workingday + 
                     weathersit + temp + hum + windspeed,
                   data = train,
                   kernel = "radial",
                   cost = 10,
                   gamma = 0.1)
  # Save model
  saveRDS(svm_model, "models/svm_model.rds")
}

# Predictions and performance
svm_pred <- predict(svm_model, newdata = test)
svm_accuracy <- mean(svm_pred == test$high_demand)
svm_conf <- table(Predicted = svm_pred, Actual = test$high_demand)

cat("\nSVM Performance:\n")
cat("Accuracy:", round(svm_accuracy * 100, 1), "%\n")
print(svm_conf)
```

**Interpretation**: SVM achieves comparable accuracy to neural networks with potentially better generalization on new patterns. The radial kernel captures complex boundaries between high/low demand states.

**Business Value**: Provides complementary classification for ensemble decision-making; reduces false negatives (missed high-demand periods).

\newpage

# Model Comparison and Cross-Validation

We perform 5-fold cross-validation on SVMs with different hyperparameters to optimize classification:

```{r cv-svm}
# Cross-validation for SVM cost parameter
cost_values <- c(1, 10, 100)
cv_results <- data.frame(Cost = numeric(), Accuracy = numeric())

for (cost_val in cost_values) {
  cv_folds <- createFolds(train$high_demand, k = 5)
  fold_accuracy <- numeric(5)
  
  for (i in 1:5) {
    fold_train <- train[-cv_folds[[i]], ]
    fold_valid <- train[cv_folds[[i]], ]
    
    svm_cv <- svm(high_demand ~ season + yr + hr + holiday + workingday + 
                    weathersit + temp + hum + windspeed,
                  data = fold_train,
                  kernel = "radial",
                  cost = cost_val,
                  gamma = 0.1)
    
    fold_pred <- predict(svm_cv, fold_valid)
    fold_accuracy[i] <- mean(fold_pred == fold_valid$high_demand)
  }
  
  cv_results <- rbind(cv_results, 
                      data.frame(Cost = cost_val, 
                                Accuracy = mean(fold_accuracy)))
}

cv_results %>%
  kable(digits = 3, caption = "SVM Cross-Validation Results")
```

**Findings**: Cost parameter of 10 provides optimal balance between complexity and generalization.

## Overall Model Performance Summary

```{r performance-summary}
# Compile all performance metrics
performance <- data.frame(
  Model = c("Linear Model", "GAM", "Poisson GLM", "Binomial GLM", 
            "Neural Network", "SVM"),
  Task = c("Total Demand", "Total Demand", "Casual Users", "User Composition",
           "High Demand Class", "High Demand Class"),
  Metric = c(paste("RMSE:", round(lm_rmse, 2)),
             paste("RMSE:", round(gam_rmse, 2)),
             paste("RMSE:", round(glm_pois_rmse, 2)),
             paste("Accuracy:", round(glm_binom_accuracy * 100, 1), "%"),
             paste("Accuracy:", round(nn_accuracy * 100, 1), "%"),
             paste("Accuracy:", round(svm_accuracy * 100, 1), "%")),
  Business_Use = c("Daily forecasting", "Weather-sensitive forecasting",
                   "Marketing targeting", "Membership strategy",
                   "Alert system", "Operational planning")
)

kable(performance, caption = "Model Performance and Business Applications")
```

\newpage

# Conclusions

## Key Findings

Our comprehensive analysis reveals five actionable insights for optimizing bike-sharing operations:

1. **Temporal Patterns Drive Demand**: Clear commuter peaks (8am, 5-6pm) and seasonal variation (Fall peak, Spring trough) enable predictable bike allocation. The 2011-2012 growth trajectory (~2x increase) demonstrates market expansion potential.

2. **Weather Sensitivity Varies by Metric**: Temperature optimum around 0.6-0.7 normalized scale; light rain reduces demand by 40%. However, weather has minimal effect on registered vs. casual user composition, suggesting loyal riders adapt while casual users avoid adverse conditions.

3. **User Segmentation Informs Strategy**: Registered users dominate working days (82%), while casual users increase weekends. This validates targeted approaches: commuter-route optimization weekdays, leisure-route emphasis weekends.

4. **Nonlinear Relationships Matter**: GAM reveals complex weather effects missed by linear models, particularly temperature's inverted-U relationship. This justifies dynamic pricing/availability strategies.

5. **Classification Models Enable Proactive Management**: Neural networks and SVMs predict high-demand periods with >85% accuracy, allowing proactive bike redistribution before shortages occur.

## Operational Recommendations

**Immediate Actions** (Next Quarter):
- Implement hour-based bike allocation: 40% surplus at 7-9am and 5-7pm near business districts
- Launch targeted casual-user campaigns during holidays/weekends at scenic routes
- Install weather-protected stations in high-wind or frequent-rain areas

**Strategic Initiatives** (Next Year):
- Deploy high-demand alert system using NN/SVM ensemble
- Expand Fall capacity (+30% fleet) to capitalize on peak seasonal demand
- Develop two-tier pricing: dynamic pricing for casual users, stable rates for registered users

## Limitations

While our models demonstrate strong predictive power, several limitations warrant consideration:

1. **Data Scope**: Analysis based on 2011-2012 data; post-pandemic behavior may differ significantly
2. **External Factors**: Models omit events (concerts, sports), construction, or transit disruptions
3. **Spatial Dynamics**: Hourly aggregates mask station-level variation; neighborhood-specific models would improve redistribution logistics
4. **Causal Inference**: Predictive models identify correlations but cannot confirm causal mechanisms (e.g., weather causes demand vs. both influenced by third factor)

## Future Work

To enhance decision-support capabilities, we recommend:

1. **Spatial Modeling**: Develop station-level forecasts using geographic data and network flow analysis
2. **Temporal Granularity**: 15-minute predictions for intra-hour variability during peak periods
3. **Ensemble Methods**: Combine model predictions (e.g., weighted average of LM, GAM, NN) for robust forecasts
4. **Real-time Integration**: Deploy models via API for live dashboard updating as conditions change
5. **Causal Analysis**: Conduct A/B tests for pricing/availability interventions to validate model assumptions

\newpage

# Use of Generative AI

## How We Used Generative AI

Throughout this project, generative AI (primarily Claude and ChatGPT) served as a coding assistant and conceptual guide:

- **Code Generation**: Assisted with ggplot2 syntax for complex visualizations, particularly multi-panel plots and custom themes
- **Debugging**: Helped identify issues with GAM convergence and neural network scaling
- **Explanation**: Clarified interpretation of GLM coefficients on log/logit scales
- **Text Refinement**: Improved clarity of technical descriptions for non-technical stakeholders

## What Was Easy/Hard/Impossible

**Easy Tasks**:
- Generating boilerplate code for data loading, splitting, and standard visualizations
- Explaining statistical concepts (e.g., "What does deviance mean in Poisson GLM?")
- Formatting suggestions for R Markdown (e.g., table alignment, figure sizing)

**Hard Tasks**:
- Domain-specific business interpretation: AI provided generic insights, but connecting model outputs to bike-sharing operations required our judgment
- Debugging context-specific errors: AI suggestions for error messages often missed nuances of our dataset structure
- Balancing model complexity with interpretability: AI tended to suggest overly complex models

**Impossible Tasks**:
- Understanding our client's actual priorities and constraints (AI cannot replace stakeholder interviews)
- Making final modeling decisions: Which interactions to include in LM? What GAM smoothness? These required subject-matter expertise
- Validating reasonableness of results: AI couldn't assess whether "40% demand reduction in rain" aligned with real-world bike-sharing behavior

## Critical Evaluation

We exercised caution when using AI-generated content:

1. **Code Verification**: Always tested code snippets independently; AI occasionally suggested outdated function arguments or incompatible package versions
2. **Statistical Accuracy**: Cross-referenced AI explanations with textbooks and documentation; AI sometimes confused conditional vs. marginal effects
3. **Contextual Appropriateness**: AI recommended techniques (e.g., random forests) we hadn't covered in class; we stuck to course requirements
4. **Reproducibility**: Ensured all AI-assisted code was transparent and well-commented so others could understand our logic

Overall, generative AI accelerated routine tasks but required active oversight for statistical rigor and business relevance. It served as a "knowledgeable assistant" rather than a substitute for critical thinking.

\newpage

# Appendix: Session Information

```{r session-info}
sessionInfo()
```